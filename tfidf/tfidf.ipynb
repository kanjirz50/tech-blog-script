{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDFを適用する\n",
    "\n",
    "## モジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:27:53.055081Z",
     "start_time": "2018-08-30T00:27:52.197049+09:00"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.tokenizer import Tokenizer\n",
    "from janome.tokenfilter import POSKeepFilter, CompoundNounFilter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解析器インスタンスの作成\n",
    "janomeのAnalyzerクラスを利用します。\n",
    "複合名詞処理をした後に、名詞のみをフィルタリングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:27:54.816048Z",
     "start_time": "2018-08-30T00:27:53.059048+09:00"
    }
   },
   "outputs": [],
   "source": [
    "a = Analyzer(token_filters=[CompoundNounFilter(), POSKeepFilter(\"名詞\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文書集合を読み込む\n",
    "globでファイル一覧を取得し、1ファイルずつ読み込みます。\n",
    "一つのファイルは一つの文書として、docsに追加されます。\n",
    "\n",
    "一つの文書はスペース区切りの単語で構成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for f in glob.glob(\"./docs/*.txt\"):\n",
    "    with open(f, \"r\", encoding=\"utf-8\") as fin:\n",
    "        doc = []\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            doc.append(\" \".join([tok.surface for tok in a.analyze(line)]))\n",
    "        docs.append(\" \".join(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDFベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:25:49.852770Z",
     "start_time": "2018-08-30T00:25:49.841827+09:00"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vector = vectorizer.fit_transform(docs)\n",
    "\n",
    "feature_names = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要な単語上位10件を表示\n",
    "TF-IDFスコアが高い単語上位10語を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:25:50.309866Z",
     "start_time": "2018-08-30T00:25:50.296767+09:00"
    }
   },
   "outputs": [],
   "source": [
    "for vec in vector:\n",
    "    index = np.argsort(vec.toarray(), axis=1)[:,::-1]\n",
    "    feature_words = feature_names[index]\n",
    "    print(feature_words[:,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 元ネタとなっている文書を表示する\n",
    "複合名詞処理＋名詞フィルタリングをした文書を先頭から200文字表示する。\n",
    "前で示した上位10件が特徴づける単語になっているか確認でき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T15:25:50.705768Z",
     "start_time": "2018-08-30T00:25:50.695801+09:00"
    }
   },
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc[:200])\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
